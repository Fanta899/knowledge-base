
# 1 std::vector
std::vector 扩容
* 申请空间：通常按 1.5 倍或 2 倍增长。
* 元素迁移：这是关键！它不是简单的 memcpy。
    * 如果元素定义了 noexcept 移动构造函数，vector 会调用移动构造函数把元素“偷”到新家。
    * 如果没有移动构造函数，它会退而求其次调用拷贝构造函数（虽然慢，但保证安全）。
* 销毁旧家：调用旧位置元素的析构函数，并释放旧内存。

核心优化技术：reserve() 与 emplace_back()
* 避免频繁扩容：reserve()
```cpp
std::vector<int> v;
v.reserve(1000); // 直接分配 1000 个人的座位，但还没坐人
```
* 避免临时对象：emplace_back()
```cpp
struct Point {
    Point(int x, int y) {}
};

std::vector<Point> v;
v.push_back(Point(1, 2));  // 1. 创建临时对象 2. 拷贝/移动进 vector 3. 销毁临时对象
v.emplace_back(1, 2);      // 直接在 vector 内存里构造 Point，0 次拷贝！
```

扩容对指针的影响
这是 C 程序员最容易掉进去的坑——迭代器失效（Iterator Invalidation）。

```cpp
std::vector<int> v = {1, 2, 3};
int* p = &v[0]; // 拿到第一个元素的地址

v.push_back(4); 
v.push_back(5); // 假设这里触发了扩容（重新分配内存）

// 💣 危险！此时 p 指向的是已经被释放的旧内存！
// std::cout << *p << std::endl;
```
在 C 语言中，如果你 realloc 了指针，原指针也可能失效。在 C++ 中，这种风险同样存在。

**重点： 如果你把 SmartBuffer 移动构造函数后的 noexcept 删掉，再运行程序，你会发现 vector 扩容时变怂了——它会改用拷贝。这就是 C++ 的“异常安全保证”**

---

# 2 std::unordered_map
基于 **哈希表** 实现的，提供了平均时间复杂度为 $O(1)$ 的查找、插入和删除效率。
底层结构：桶（Buckets）
std::unordered_map 的底层通常是一个数组，每个元素被称为一个 **“桶（Bucket）”**。
* 冲突处理：当两个不同的键产生相同的哈希值时，C++ 标准库默认使用链地址法（即每个桶后面挂一个链表）
* 负载因子（Load Factor）：当元素数量与桶数量的比值超过某个阈值（默认是 1.0）时，它会自动触发 Rehash（重新哈希），即申请更大的内存并重新分布所有元素

C 程序员必知的性能陷阱
虽然 unordered_map 很好用，但相比于 vector，它有几个明显的开销：
* 内存不连续：由于使用了链地址法，节点在内存中是分散的，这对 CPU 缓存（Cache）不友好。如果你的数据量很小（比如只有 10 个元素），用 vector 配合 std::find 往往比 unordered_map 更快。

* 哈希开销：每次插入或查找都要计算哈希值。如果你的键是很长的字符串，计算哈希可能比比较字符串更耗时。

优化建议： 如果你预先知道要存多少数据，同样可以使用 reserve() 来避免多次 Rehash。

什么时候用 std::map vs std::unordered_map？

| 特性 | std::map | std::unordered_map |
| ------ | ---- | --------- |
| 底层实现 | 红黑树 (平衡二叉树) | 哈希表 |
| 查找复杂度 | $O(\log n)$ | 平均 $O(1)$，最坏 $O(n)$
| 元素顺序	| 有序（按 Key 排序） |	无序 |
| 适用场景	| 需要按顺序遍历，或需要范围查询  |	只追求最快的查找速度 |

键值（Key）是如何变成哈希值的？
哈希值的生成是由 std::hash\<Key\> 这个仿函数完成的。对于不同的数据类型，它的策略不同：

A. 整数类型：简单直接
对于 int、long 等类型，std::hash 通常直接返回原值（或者强转为 size_t）。
* 原因：整数本身已经分布得很好了，没必要再浪费 CPU 去算复杂的算法。

B. 字符串类型：核心算法
对于 std::string，不能直接用地址，必须根据内容计算。目前主流编译器（GCC, Clang）通常使用 MurmurHash 或 FNV-1a。

以 FNV-1a 为例，它的 C 伪代码极其简单高效：
```cpp
uint64_t fnv1a_hash(const char* str) {
    uint64_t hash = 0xcbf29ce484222325; // 初始偏移量（Offset Basis）
    while (*str) {
        hash ^= (uint8_t)*str++;       // 异或当前字符
        hash *= 0x100000001b3;         // 乘以一个巨大的质数（FNV prime）
    }
    return hash;
}
```

通过不断的异或和质数乘法，哪怕字符串只差一个字母，最终产生的 size_t 结果也会天差地别。

为什么会产生相同的哈希值?
第一层：哈希值碰撞（数学上的必然）
* 原理：size_t 在 64 位系统下虽然很大（$2^{64}$），但它是有限的。而理论上 Key 的组合是无限的（比如你可以写无限长的字符串）。
* 结论：根据“鸽巢原理”，必然存在两个不同的 Key 指向同一个 size_t 数值。只不过在好的算法下，这种概率极低。

第二层：索引碰撞（工程上的必然）这是最常见的冲突。虽然 hash("Alice") 和 hash("Bob") 产生的 size_t 不同，但 unordered_map 内部的 **桶** 数量是有限的（比如初始只有 13 个桶）。
* 计算索引：index = hash_value % bucket_count;
* 冲突发生：
    * hash("Alice") = 1234567 -> 1234567 % 13 = 5
    * hash("Bob")   = 9876548 -> 9876548 % 13 = 5

* 结果：即便哈希值本身不同，但取模后它们都要挤进 5 号桶。

C++ 如何处理这些碰撞？
当两个 Key 掉进同一个桶时，std::unordered_map 默认使用 链地址法（Chaining）：

* 每个桶（Bucket）本质上是一个链表的头指针。
* 当 "Alice" 和 "Bob" 都映射到 5 号桶时，5 号桶的链表里就会有两个节点。
* 查找过程：
    * 先算哈希，找到 5 号桶。
    * 遍历 5 号桶的链表。
    * 关键点：此时会调用 Key 的 operator==。这就是为什么自定义类型作为 Key 时，既要提供哈希函数，又要重载 == 的原因。

性能的关键：负载因子（Load Factor）

如果桶很少，数据很多，链表就会变得很长，$O(1)$ 的查找就会退化成 $O(n)$。
* 负载因子 = 元素总数 / 桶数。
* Rehash：当负载因子超过阈值（通常是 1.0）时，unordered_map 会自动申请更多的桶（通常翻倍），并把所有元素重新分配一遍。这就像 C 语言里的 realloc，非常耗时。

C 程序员的优化直觉：如果你知道要存 1000 个元素，提前调用 my_map.reserve(1000);。这会一次性分配好足够的桶，避免多次 Rehash 带来的性能抖动。

---

# 3 std::deque
**内存布局：分段连续（The Map of Chunks）**

这是 std::deque 最核心的底层逻辑。它不像 vector 那样只有一块巨大的连续内存，也不像 list 那样每个节点都散落在各处。
底层结构：
* 它维护了一个中控图（Map），本质上是一个指针数组。
* 每个指针指向一块固定大小的连续内存分段（Chunk/Node）。

给 C 程序员的类比： 想象你有一个动态数组（中控图），数组里的每个元素都是一个指向 malloc 出来的 512 字节 缓冲区的指针。

与 vector 对比
| 特性      | std::vector   | std::deque |
| ------ | ---- | --------- |
| 头端插入/删除    | $O(n)$（需要整体平移）|   $O(1)$（直接在首个 Chunk 操作）|
| 尾端插入/删除    | $O(1)$（需考虑重分配）|   $O(1)$  |
| 随机访问 []      |$O(1)$（一次加法）    |   $O(1)$（两次跳转：先找 Chunk，再找偏移）|
| 内存连续性       |完美连续              |   分段连续  |
| 扩容代价         |极高（需拷贝整个数组） |   极低（只需增加新的 Chunk 指针）|

在 vector 中，任何 push_back 都可能触发 realloc 导致所有指针失效。 在 deque 中：

* 在两端插入元素时，现有的元素指针和引用不会失效！（因为旧的 Chunk 没动，只是在新的位置开了辟了新空间）。
* 只有迭代器本身（记录位置的游标）可能会因为中控图的变动而失效。

它是 std::stack 和 std::queue 的默认底座
* 如果你在 C++ 中写 std::stack\<int\> s;，它默认其实是包装了一个 std::deque。 为什么不用 vector？ 因为 deque 不需要频繁的大规模内存拷贝，且对内存的利用率在长周期运行下更稳定。

虽然 deque 看起来很完美，但在极致性能领域，它有明显的缺点：

* Cache 不友好：虽然段内是连续的，但跳段时会发生 Cache Miss。如果你是遍历海量数据，vector 依然是王者。
* 管理开销：deque 的迭代器非常复杂（它需要判断是否到了 Chunk 的末尾并跳转到下一个 Chunk），这导致它的遍历速度通常比 vector 慢 2-5 倍。

---

# 4 std::list (双向链表) 与 std::forward_list (单向链表)
在 C 语言中，手写一个带 head 和 tail 的双向链表是基本功。C++ 的 std::list 封装了这一切。

* 底层结构：
  * 每一个节点都是一个独立的 new 出来的内存块，通过 prev 和 next 指针相连。
* 特点：
  * 插入/删除效率极高：只要你拿到了迭代器（指针），在任何位置插入或删除都是 $O(1)$，且不会引起其他元素的移动。
  * 迭代器永不失效：除非你删掉那个节点，否则指向它的指针永远有效。
* C 程序员的槽点：
  * Cache 极度不友好：节点在堆上到处乱跳，遍历速度比 vector 慢得多。
  * 内存浪费：每个 int 节点都要额外搭上 16 字节的指针空间（64位系统）。

std::forward_list (C++11)：这是为了追求极致轻量化设计的单向链表。它比 list 少一个指针，甚至没有 size() 方法（因为存长度会多占内存）。如果你在 C 里需要一个最简单的 struct node* 链表，选它。

---

# 5 std::map 与 std::set
这是 C 语言标准库完全缺失的部分。

* 底层结构：红黑树 (Red-Black Tree)。
* 核心逻辑：
  * 与 unordered_map 不同，map 里的元素是严格按键（Key）排序的。
  * 查找、插入、删除的时间复杂度都是稳定的 $O(\log n)$。
* 使用场景：
  * 你需要数据始终保持有序（比如按时间戳排序的日志）。
  * 你需要范围查找（比如找到所有 Key 在 10 到 100 之间的元素）。
  
std::set：可以理解为只有 Key 没有 Value 的 map。它会自动去重并排序。

---

# 6 std::array
本质：它就是对 C 原生数组的薄封装。

为什么用它？

* 不会退化为指针：在 C 语言中，把数组传给函数会退化为 int*，丢失长度信息。std::array 传参时保留类型和长度。
* 支持 STL 算法：你可以直接对它使用 std::sort 或 std::find。
* 性能：它分配在栈上，没有任何动态内存开销，性能与原生数组完全一致。

---

# 7 容器适配器 (Container Adapters)
这些不是新的数据结构，而是对现有容器的“限制包装”。

* std::stack (栈)：后进先出 (LIFO)。默认基于 deque 实现。
* std::queue (队列)：先进先出 (FIFO)。默认基于 deque 实现。
* std::priority_queue (优先队列)：底层是一个二叉堆 (Heap)，默认基于 vector。
  * C 程序员视角：如果你在写任务调度器，需要每次取出优先级最高的任务，这就是现成的工具。

---

# 8 一些面试常见问题
## 8.1. 迭代器失效 (Iterator Invalidation) —— 面试必问 Top 1
在 C 语言中，如果你 realloc 了一个指针，原指针可能变野指针。C++ 中这叫“迭代器失效”。

* Vector：
  * 插入元素：如果触发扩容，所有迭代器、指针、引用全部失效。如果没有扩容，插入点之后的失效。
  * 删除元素：删除点之后的全部失效。

* List / Map / Set：
  * 极其坚挺。删除一个节点，只有指向该节点的迭代器失效，其他完全不受影响。

* Deque：
  * 在首尾插入：迭代器会失效，但指向元素的指针和引用通常不失效（因为旧的存储块没动）。这是它的绝活。

面试题： “如何在遍历 vector 的过程中删除满足条件的元素？”

* 错误做法：在 for 循环里 erase(it) 然后 it++。
* 正确做法：使用 it = vec.erase(it) 获取下一个有效的迭代器，或者用 std::remove_if (Erase-remove 惯用法)。

---

# 8.2 emplace_back 到底比 push_back 强在哪？
作为 C 程序员，你一定在意减少不必要的内存拷贝。

* push_back：先创建一个临时对象（调用构造函数），然后将它拷贝或移动到容器里，最后销毁临时对象。
* emplace_back：利用了参数转发（Perfect Forwarding），直接在容器预留的内存位置上构造对象。

面试陷阱：并不是所有时候 emplace_back 都快。如果对象已经存在了，两者没区别。它真正的威力在于：你可以直接传构造函数的参数，而不是传对象。
```cpp
v.push_back(Item(1, "test"));    // 产生临时对象，触发拷贝/移动
v.emplace_back(1, "test");       // 原位构造，无临时对象
```

---

# 8.3 容器的内存“只增不减”现象
这是 C 程序员在做长周期服务时最头疼的问题。

如果你有一个 vector\<int\> v，里面存了 100 万个元素，然后你调用 v.clear()。

* 结果：v.size() 变成 0，但 v.capacity() 依然是 100 万。这块内存并没有还给操作系统！

面试题： “如何强制释放 vector 占用的多余内存？”

* C++11 答案：v.shrink_to_fit();
* 老版本通用答案（黑话：Swap 技巧）：std::vector<int>().swap(v); （通过与一个空的 vector 交换，强制释放原内存）。

---

# 8.4 那个“奇葩”的 vector\<bool\>
这是 C++ 标准库里公认的一个“设计失误”，但面试官很爱问。

* 真相：vector\<bool\> 并不是一个真正的容器，它是一个特化版本。
* 底层：为了节省内存，它内部使用 Bit-packing（位包装），一个 bool 只占 1 个 bit，而不是 1 个字节。
* 代价：
  * 你无法取其中元素的地址（&v[0] 编译报错），因为 CPU 无法直接寻址一个 bit。
  * 它返回的是一个“代理对象”，不是真正的 bool&。
* 结论：如果你需要真正的布尔数组且不计较那点内存，请用 vector\<char\> 或者 std::deque\<bool\>。

总结：如何评价 vector\<bool\>？

它是一个 **“抽象泄漏”** 的典型案例：为了底层性能优化，牺牲了上层的语义一致性。

* 优点：省内存（1/8）。
* 缺点：不支持取地址、非线程安全、易引发 auto 悬空指针、破坏泛型。

---

# 8.5 各容器的“空间开销” (Memory Overhead)
面试官可能会考你对内存分配的精细控制：

* vector：最省内存。开销仅为 3 个指针（指向头、尾、可用空间末尾，共 24 字节）。
* list：最费内存。每个节点除了数据，还要存两个指针（prev, next）。存一个 char 可能要搭上 16 字节开销。
* unordered_map：内存大户。除了数据，还要维护桶数组、哈希节点指针、负载因子控制块。

---

# 8.6 扩容因子为什么是 1.5 或 2？
为什么 vector 扩容时不是 size + 1，也不是 size * 10？

* +1 的问题：每次插入都要 realloc，复杂度退化成 $O(n^2)$。
* 倍数扩容：可以保证插入的摊还时间复杂度（Amortized Time） 是 $O(1)$。
* 1.5 vs 2：
  * 很多教材说 2 倍。
  * 但高性能实现（如 MSVC）倾向于 1.5 倍。因为 1.5 倍可以更好地复用之前释放掉的内存块（数学证明：如果是 2 倍，新申请的内存永远比之前所有块的总和大，无法利用前面的碎块）。